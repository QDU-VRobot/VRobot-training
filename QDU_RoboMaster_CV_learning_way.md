#### 计算机扫盲

在一切的一切开始之前，我们要先进行计算机扫盲！

要了解计算机的组成、基本使用方法，以及进行程序开发必备的计算机知识。

一些必须了解的知识点：进程（Process）、命令行（Terminal、Power Shell、Command Prompt）、环境变量（Environment Variables）

推荐课程：[计算机教育中缺失的学期](https://www.bilibili.com/video/BV1JkzGYuEGo?vd_source=da62262bf27813a6ac6525bc0cfa79a6)（可能不包括以上列出的知识点，请自行搜索了解）

完成以上任务后，为了方便此后的学习，请去了解Markdown格式与如何利用Latex写公式，并搭建自己的梯子。（这份文档也是用Markdown编辑器Typora写的）





#### 语言学习

做好准备之后，接下来从编程语言开始入手吧。



##### 开发环境配置

在开始编程之前，我们需要先配置开发环境。一个舒适的开发环境是高效编程的重要前提。在这里我推荐以下两个IDE：

**CLion**、**VS Code**

CLion配置简单、易上手，界面友好，缺点是内存负荷重。

VS Code配置稍复杂，但可玩性强，且足以one for all，应对几乎所有场景的开发。

配置过程请**自行寻找教程**，这也是考验你**自学能力**的一部分哦~

> IDE是**集成开发环境**（Integrated Development Environment）的英文缩写。简单来说，它不是一个单一的工具，而是一个将程序员在软件开发过程中所需要的多种工具整合在一起的软件包，旨在提高程序员的工作效率。
>
> 一个合格的IDE通常包含**源代码编辑器**、**自动化构建工具**、**调试器**。

在构建工具配置完后，接着可以尝试配置**调试器**（Debugger）。

在你写下第一行代码之前，有一个比学习语法更重要的技能需要掌握：**调试**（Debugging）。

一个残酷但真实的现实是：我们的大部分时间并不是在“写”代码，而是在“调”代码。学会使用调试器，是区分业余爱好者和专业开发者的第一道分水岭。

你必须掌握的调试器核心操作：

**断点**：在你认为可能出问题的代码行左侧单击，设置一个“停止标志”。当程序运行到这一行时，就会自动暂停。

**步进**：

​			单步跳过：执行当前行，然后停在下一行。如果当前行是一个函数调用，它会执行完整个函数，而不会进入函数内部。

​			单步进入：如果当前行是一个函数调用，它会进入该函数内部的第一行暂停，让你能逐行调试函数内部的逻辑。

​			单步跳出：如果你已经在一个函数内部，这个操作会执行完该函数余下的所有代码，然后停在调用该函数之后的那一行。

**继续**：让程序从当前暂停的位置继续正常运行，直到遇到下一个断点或程序结束。

**监视变量**：在程序暂停时，IDE的调试窗口会自动显示当前作用域内所有变量的值。你也可以手动添加你想持续关注的变量或表达式，观察它们如何随着程序的运行而变化。

CLion 和 VS Code 都内置了强大的图形化调试器，配置也非常简单。请**务必自行搜索教程**，学会如何为你的C/C++项目启动一个调试会话。



##### C语言

要进行编程思维的培养，从c语言开始是最为经典的学习路径。



推荐课程：[高级程序设计语言（C语言程序设计）课堂实录](https://www.bilibili.com/video/BV1DV4y1T7LV?vd_source=da62262bf27813a6ac6525bc0cfa79a6)（精讲，时间充裕可选）、[【浙江大学】C语言入门与进阶 翁恺（全129讲）](https://www.bilibili.com/video/BV1XZ4y1S7e1?vd_source=da62262bf27813a6ac6525bc0cfa79a6)（较经典）

学习资源：[洛谷](https://www.luogu.com.cn/)（主要完成入门难度题目）、[PTA](https://pintia.cn/problem-sets/dashboard)（完成部分天梯赛模拟题）

（其实没有多难来着，主播当初半个月不到就速通了，不要过高估计学习难度哦



小作业：完成题目 <a href="# 佐罗与魔法石板">佐罗与魔法石板</a>、<a href="# 切分表达式">切分表达式</a>



稍有难度的兴趣向扩展学习：C语言的其中一个巨大优势在于能轻松地和硬件交互。请购置一块STM32F103C8T6开发板与一块STLink（或前往实验室找我借用也行），根据网上的教程配置好开发环境（Keil、STM32CubeMX、VS Code等等），点亮led灯泡，实现与电脑的串口通信，通过电脑发送至串口的信息控制led。（如果在做这个学习任务时感觉有点兴趣，可以再考虑考虑软件组



##### C++、数据结构与算法

c++是基于c语言的面向对象编程语言，我们的算法程序绝大部分由c++编写。了解基础语法，理解面向对象的含义，并熟练掌握各种常用的STL（标准模板库）即可。

主要需要学习的知识点：命名空间（Namespace）、类（Class）、重载（Overload）、引用（Reference）、模板（Template）、标准模板库（STL，Standard Template Library）、Lambda表达式、智能指针（Smart Pointer）、异常（Exception）等等c++特性；

数组（Array）、栈（Stack）、队列（Queue）、哈希表（Hash Map）、图（Graph）、优先队列（Priority_queue）等等常用数据结构；

了解排序、查找、贪心、动态规划、DFS、BFS等基础算法。

> 此算法非彼算法！“算法组”中的算法指的是解决如自瞄、导航、决策等等具体问题的算法，此处出现的算法指的是利用计算机等优化解决通用计算任务的算法。



推荐课程：[面向对象设计C++-- 浙江大学 -- 翁恺](https://www.bilibili.com/video/BV1yQ4y1A7ts?vd_source=da62262bf27813a6ac6525bc0cfa79a6)、[【百万好评】国外大神！！油管千万级收藏，C++技术大佬带你从入门到精通，新手快速进阶！全中文字幕，学不会我退出IT界](https://www.bilibili.com/video/BV1Dk4y1j7oj?vd_source=da62262bf27813a6ac6525bc0cfa79a6)

学习资源：[还是洛谷嘿嘿](https://www.luogu.com.cn/)、[LeetCode](https://leetcode.cn/)（主要完成简单难度题目）

（有了c语言的基础，这里的难点只在于面向对象的各种概念、数据结构与算法



小作业：完成题目 <a href="# 括号匹配">括号匹配</a>、<a href="# 一元多项式的乘法与加法运算">一元多项式的乘法与加法运算</a>

中作业：<a href="# String类">设计并实现一个String类</a>

中作业（选做）：<a href="# 地图模拟器">构建一个2D网格地图模拟器</a>

> 注意，从此时开始的作业请尽量撰写一个完整、详细的自述文件（README.md）



##### Python

python是一门相对简单（？）的语言，其语法与c和c++相比要简洁很多很多很多......，要学会其基础语法是比较简单的。

学会如何创建环境、导包用包、基础语法即可。



推荐视频：[黑马程序员python教程](https://www.bilibili.com/video/BV1qW4y1a7fU?vd_source=da62262bf27813a6ac6525bc0cfa79a6)（零基础学IT能不能月薪过万暂且存疑，但这个课讲的确实不赖）





#### 进阶前置

有了一定的基础，接下来将进一步进阶。在此之前，我们还需要一些前置知识与工具

##### Linux

此前我们可能习惯在Windows下进行学习，这对于入门编程非常友好。然而，当你踏入机器人工程的专业领域，你会发现**绝大多数开发都发生在Linux系统上**。

从Windows迁移到Linux，不是一个“偏好”问题，而是一个**“必要”**问题。

**为什么必须切换到Linux？**

我们之后要学习的**机器人操作系统（ROS/ROS2）** 原生且主要支持Ubuntu。所有ROS的工具、库和社区支持都围绕Linux构建。在其他系统上使用ROS会遇到无穷无尽的兼容性问题（我反正是快被搞疯了）。

而几乎所有机器人传感器（激光雷达、摄像头、IMU）和硬件平台的驱动程序都优先为Linux开发。在Linux上，你能够更轻松地与底层硬件打交道。

要使用Linux系统，你可以选择：

1. **虚拟机 (VirtualBox/VMware)：** 最安全、最适合初学者的方案。（但是会有点逊啦，并且无法发挥电脑全部性能）
2. **Windows Subsystem for Linux (WSL2)：** 性能出色，与Windows无缝集成。（方便，但串口不见了喵）
3. **双系统：** 能发挥全部硬件性能，但安装稍复杂。

从现在开始，请强迫自己尽可能在Linux环境下完成你的编程作业和项目，尽快熟悉它的文件系统和命令行操作，同时开始把自己当作一名工程师与开发者（而非单纯的电脑使用者）来思考问题吧！

安装教程请**自行上网查阅**，为了兼容性考虑，务必安装Ubuntu 22.04 LTS。



学习资源：[Linux 101](https://101.lug.ustc.edu.cn/)



小作业：<a href="# 终端基础命令">学习终端的基础命令</a>



##### **CMake**

我们接下来将要对于c++这门语言本身进一步深入，去了解其编译为可执行文件的过程（这个过程将在本文档[附录]()中给出）。

C++是RM绝大多数队伍架构采用的基石语言。理论上，任意一个C++程序都可以用g++ 来编译。但当程序规模越来越大时，一个工程可能有许多个文件夹和源文件，这时输入的编译命令将越来越长。一个更真实的C++项目往往不是单层结构，而是由多个子目录和模块构成的。通常，一个小型 C++ 项目可能含有十几个类，各类间还存在着复杂的依赖关系。其中一部分要编译成可执行文件，另一部分编译成库文件。如果仅靠 g++ 命令，则需要输人大量的编译指令，整个编译过程会变得异常烦琐因此，对于 C++项目，使用一些工程管理工具会更加高效。

CMake就是一个方便的C++工程管理工具。



推荐课程：[软件构建: CMake 快速入门](https://www.bilibili.com/video/BV1rR4y1E7n9?vd_source=da62262bf27813a6ac6525bc0cfa79a6)、[IPADS新人培训第二讲：CMake](https://www.bilibili.com/video/BV14h41187FZ?vd_source=da62262bf27813a6ac6525bc0cfa79a6)

学习资源：[CMake保姆级教程](https://subingwen.cn/cmake/CMake-primer/)



小作业：对于c++部分的中作业（String类或地图模拟器），将其项目重构为以下**层级结构**：

```
project_root/
├─ src/                  # 存放核心逻辑，编译为库
│  ├─ YourClass.cpp
│  ├─ YourClass.hpp
│  └─ CMakeLists.txt     # 用于编译src目录下的源文件为一个库
├─ app/                  # 存放主程序
│  ├─ main.cpp
│  └─ CMakeLists.txt     # 用于编译main.cpp为一个可执行文件
└─ CMakeLists.txt        # 顶层CMakeLists，负责管理整个项目
```

在这个结构中：

1. `src/CMakeLists.txt` 负责将 `YourClass.cpp` 编译成一个静态库或动态库。
2. `app/CMakeLists.txt` 负责将 `main.cpp` 编译成一个可执行文件，并链接到 `src` 中生成的库。
3. 顶层的 `CMakeLists.txt` 使用 `add_subdirectory()` 命令来包含 `src` 和 `app` 目录，协调整个编译流程。

请自行查阅资料，学习如何编写这三个`CMakeLists.txt`文件，并成功编译运行你的项目。



##### Git、Github

你是否有过这样的经历：文档-最终版.docx, 文档-最终版修改版.docx, 文档-真的最终版.docx... 这种手动备份方式混乱且低效。Git通过**提交（commit）**、**分支（branch）**和**合并（merge）**等机制，彻底解决了这个问题，让你的项目历史清晰可追溯。

Git的核心功能是跟踪一个项目中所有文件的每一次修改。无论你写的是代码、论文还是报告，Git都能帮你记录下从第一个字开始的所有版本历史。而配合Github等在线平台则能够更方便地进行多人协作开发。

安装Git请**自行上网查阅**。





#### 机器视觉

终于到了算法组最重要的部分之一——机器视觉的学习了。

从这里开始，算法组与软件组之间将开始真正意义上不同的学习内容。

在开始之前，请你思考一下，要实现一套自瞄算法，算法流程是什么？

最简单直观的流程为：检测、追踪、解算、执行！

**检测**：从摄像头传回的一帧帧图像中，找到装甲板在哪里。

**追踪**：在连续的图像帧中，确认这块装甲板和上一帧的是同一个目标。

**解算**：根据装甲板在图像中的位置、大小以及相机的参数，计算出它在真实三维空间中的坐标。

**执行**：将三维坐标转换为云台需要转动的角度，并发送指令给电控，驱动云台瞄准、发射。



##### 检测

不论如何，我们都需要能够检测到装甲板在当前帧图像中的位置。要实现这一目的，我们需要**图像处理**技术。接下来我们将学习OpenCV——开源计算机视觉库。

出于兼容性考虑，请安装 OpenCV4.5.4。在Ubuntu中可直接通过apt安装，也可以通过源码编译安装。

一个小小的学习建议：我们在入门时不需要去死磕工具库内部算法究竟是怎么样的，就像我们在使用g++时也一般不会考虑其内部是如何优化代码结构的一样。OpenCV将常用的图像处理算法已经封装好了，我们在学习时只需要学会其核心数据结构（如Mat、Rect等等）、api使用方法（无需过于关心内部实现细节，了解其抽象算法即可），并在库的学习中逐渐了解图像处理算法的原理与一般流程。



推荐课程：[OpenCV4 C++ 快速入门视频30讲](https://www.bilibili.com/video/BV1i54y1m7tw?vd_source=da62262bf27813a6ac6525bc0cfa79a6)

学习资源：[OpenCV4快速入门]() 第1、2、3、5、6、7、10.1（自行查找电子书资源，或者可以找我要资源哦）



小作业：<a href="# Hello, OpenCV!">Hello, OpenCV!</a>

中作业：<a href="# 识别特定颜色的物体">识别特定颜色的物体</a>

大作业：<a href="# 简易装甲板识别">简易装甲板识别</a>



##### 解算

在开始前，我们还需要学习**线性代数**的一部分内容。

欸等等，我们不是来写代码的吗，为什么还要学数学啊？

因为解算本身就是一系列的代数和几何运算。如何用数字描述一个物体在空间中的位置和姿态，如何对一个物体进行旋转和平移，如何将物体从“相机眼中的世界”（相机坐标系）转换到“真实世界”（世界坐标系），再转换到“云台需要转动的角度”（云台坐标系）？这一切都离不开线性代数。如果你不理解这些基本概念，那么后续的相机标定、PnP解算、位姿估计等核心算法对你来说都将是无法理解的“黑盒”。

建议掌握内容：理解向量的点积、叉积的几何意义；掌握矩阵的加法、乘法、转置和求逆，理解矩阵乘法的线性变换本质；理解利用矩阵进行坐标系变换、旋转、平移等等线性操作。

 你不需要像数学专业的学生那样去抠每一个定理的严格证明，但你**必须**直观地理解上述核心概念。当你完成学习后，你应该能够回答诸如“一个3x3的旋转矩阵是如何旋转一个三维向量的？”、“为什么我们需要4x4的齐次变换矩阵？”等等问题。



推荐课程：[线性代数的本质](https://www.bilibili.com/video/BV1ys411472E?vd_source=da62262bf27813a6ac6525bc0cfa79a6)

学习资源：MIT18.06: Linear Algebra（教材链接：[Introduction to Linear Algebra](https://math.mit.edu/~gs/linearalgebra/)）



到目前为止，你已经能从2D的图像中找到装甲板了。但我们的最终目标是控制云台**在三维空间中**瞄准它。这就引出了一个核心问题：**如何从一张平面的照片，推断出目标在真实世界中的位置和朝向？**

这个从2D图像推断3D信息的过程，我们称之为**位姿解算**。它的核心思想是：我们已经**事先知道**了目标物体（比如装甲板）的**真实物理尺寸和形状**，我们把它看作一个**3D模型**。然后，我们将这个3D模型在摄像头拍到的2D图像上的**投影**（即我们识别出的装甲板轮廓）进行匹配。通过这个匹配过程，我们就能反向求解出这个3D模型在相机坐标系下的**位置（离我多远）**和**姿态（朝向何方）**。

它回答了两个关键问题：

1. **它离我多远？** —— **位置 (Position)**，通常用一个三维的**平移向量 (Translation Vector, tvec)** 来表示。
2. **它朝向何方？** —— **姿态 (Orientation/Attitude)**，通常用一个三维的**旋转向量 (Rotation Vector, rvec)** 来表示。

要完成这个求解过程，我们需要三样东西：

1. **物体的2D图像点 (Image Points)**：例如装甲板在图像上的四个顶点的像素坐标。这部分我们通过前面的图像处理和识别来获得。
2. **物体的3D模型点 (Object Points)**：这是关键的**参照物**。我们**预先定义**一个物体的三维坐标，然后根据它的实际物理尺寸，计算出物体的其他点在**这个模型坐标系下**的三维坐标。**注意，这并非我们最终要求的、在相机世界中的坐标**，而是一个不变的、作为基准的3D模型。
3. **相机的“内参” (Camera Intrinsics)**：每个相机都像人的眼睛，有它自己的“生理参数”，比如焦距、成像中心等。这些参数（被打包成相机内参矩阵和畸变系数）决定了3D世界如何投影到2D图像上。我们需要通过一个叫做**相机标定**的过程来获得它们。

有了这三样东西，我们就可以调用OpenCV中一个非常强大的函数 `cv::solvePnP` 来帮我们计算出`tvec`和`rvec`。



推荐课程：[Project2 相机标定与Pnp算法](https://www.bilibili.com/video/BV1Rv4y1n7gp?vd_source=da62262bf27813a6ac6525bc0cfa79a6)



小作业：<a href="# 相机标定">相机标定</a>

中作业：<a href="# 实时位姿解算">实时位姿解算</a>





##### 追踪

现在，你的程序已经可以实时解算出装甲板的三维坐标了。但你会很快发现新的问题：

**抖动**：你可能会发现，即使装甲板静止，计算出的三维坐标仍然在小范围内跳动。这背后的原因很复杂，既有算法层面的误差，但更主要的原因源于硬件：在放大后的图像中，装甲板的角点并非一个完美的像素点，而是模糊的一片区域，这导致每一帧检测到的像素坐标都有微小的偏差，最终反映为解算结果的抖动。如果直接把这个坐标送给云台，云台会高频“抽搐”。

**丢失**：如果某一帧因为运动模糊或遮挡导致没有识别到装甲板，你的程序就会“丢失目标”，云台就会停止移动，这在实战中是致命的。

**延迟**：整个自瞄链路存在多重延迟。首先是系统延迟，即从摄像头采集图像到程序计算出坐标，再到指令发送给电控的整个过程，这通常有几十到上百毫秒。然而，在高速对抗中，另一个延迟是弹丸的飞行时间。当你看到目标、完成计算并开火时，子弹还需要飞一段时间才能到达目标位置。在这段时间里，目标已经移动了。因此，我们的预测不仅要补偿系统延迟，更要预测出子弹飞行时间后目标的位置。

为了解决这些问题，我们需要引入**追踪 (Tracking)** 和**预测 (Prediction)**。我们的目标是建立一个目标的**运动模型**，通过融合连续多帧的信息，来估算出目标**真实、平滑**的运动状态（不仅仅是位置，还包括速度），并预测它在下一时刻的位置。

而完成这一任务最经典、最强大的工具之一，就是**卡尔曼滤波器 (Kalman Filter)**。

你不需要立刻深入它背后复杂的数学推导。从应用的角度，你可以把它理解成一个非常聪明的“数据融合”算法。

在每一帧，它都会做两件事：

**预测**：根据上一帧估算出的目标状态（如位置和速度），它会使用一个物理模型（例如匀速或匀加速运动模型）来**预测**目标在当前帧**应该**会出现在哪里。

**更新**：然后，它会把你这一帧**实际检测**到的目标位置（我们称之为“观测量”）拿过来，和它的“预测值”进行比较。如果观测量很“靠谱”（噪声小），它就多相信观测量一些；如果观测量很“不靠谱”（噪声大），它就多相信自己的预测一些。通过这种加权融合，它会得出一个当前帧**最优的估计状态**。

这个过程不断迭代，带来的好处是：

**平滑**：融合了历史信息，单帧的测量噪声会被有效滤除，得到的结果非常平滑。

**处理丢失**：如果在某一帧没有检测到目标（没有观测量），卡尔曼滤波器依然可以仅凭它的**预测**来输出一个合理的位置，让云台可以继续跟随，从而实现短暂的目标丢失追踪。

**预测**：由于我们估算出了目标的速度，我们可以轻松地预测出目标在 `t` 毫秒之后的位置，从而有效补偿系统延迟。



推荐课程：[从放弃到精通！卡尔曼滤波从理论到实践~](https://www.bilibili.com/video/BV1Rh41117MT?vd_source=da62262bf27813a6ac6525bc0cfa79a6)



大作业：<a href="# 基于卡尔曼滤波的装甲板追踪器">基于卡尔曼滤波的装甲板追踪器</a>





#### 深度学习

当你掌握了上述基于传统OpenCV的视觉处理方法后，你会发现它在某些复杂场景下（如光照剧烈变化、背景干扰严重、装甲板样式特殊等）会遇到瓶颈。这时，深度学习将为你打开一扇新的大门。

与传统方法不同，深度学习检测模型（如YOLO系列）不是依靠人工设计的规则（如颜色、形状）来寻找目标，而是通过“学习”大量的数据，自主地从图像中提取出最有效的特征。这使得它异常强大和鲁棒。

在开始前，我们需要你去了解以下概念：

**神经网络 (Neural Network)**：了解基本的神经元、层、前向传播的概念。

**卷积神经网络 (CNN)**：**这是重中之重**。理解卷积层、池化层是如何从图像中提取特征的（边缘、纹理、形状等）。

**目标检测 (Object Detection)**：理解其任务是什么（分类+定位），以及什么是边界框（Bounding Box）。了解主流的算法思想，特别是**YOLO (You Only Look Once)**，因其出色的速度和精度平衡，成为目标检测领域的首选。

**模型训练 (Training)**：理解什么是**数据集（Data Set）**、**标签（Label）**、**损失函数 (Loss Function)** 和**优化器 (Optimizer)**。明白训练的本质就是通过优化器不断调整网络参数，使得损失函数最小化。

我们此前已经学习过了Python，接下来将继续基于Python学习深度学习。

我们需要学习的是目前最流行的深度学习框架——PyTorch，建议使用 **Anaconda** 或 **Miniconda** 来管理Python环境和复杂的依赖库，同时最好拥有一台带有NVIDIA GPU的笔记本或台式机（当然AMD GPU或者只有CPU也是可以的）。



推荐课程：[《动手学深度学习》2.0.0 documentation](https://zh.d2l.ai/index.html)、[【完结】动手学深度学习 PyTorch版](https://space.bilibili.com/1567748478/lists/358497?type=series)（配套B站课程）



小作业：<a href="# 实现手写数字识别">实现手写数字识别</a>

大作业：<a href="# 构建、训练并部署一个YOLO装甲板检测器">构建、训练并部署一个YOLO装甲板检测器</a>





#### ROS2

TO BE DONE





































































### 作业附录：

#### 佐罗与魔法石板
佐罗（Zorro）是一个传奇人物，出现在很多电影（小说、动画、电视剧）中，他经常用利剑划下`Z`字标记，让我们印象深刻。

![](https://images.ptausercontent.com/93520803-6a7f-406a-8a20-1345407c06fc.jpg)

上图分别展示了在`5*5`排列的石板上所划的这四种`Z`字，尺寸为`2`至`5`（横边的长度），例如：尺寸为`3`的`Z`字划过了`7`个圆环。佐罗划`Z`的动作是：从左上角开始，水平划至右端，再斜划至左下角，最后水平划至右端。

这块石板其实是霍格沃茨学校的一名教授在某次旅行途中遗失的。佐罗划了多次后，发现了板上圆环的神奇之处：

- 普通圆环：一个普通圆环，每被划2次，产生1枚金币
- 幸运圆环：一个幸运圆环，每次被划，产生1枚金币
- 金刚圆环：硬度远超金刚石，剑不留痕，亦无金币产生。佐罗在划`Z`字时若划到一个金刚圆环，则停止、不再继续划完这个`Z`字。
- 损坏圆环：魔法石板年久失修，会有一些圆环是损坏的。剑划过损坏圆环，没有任何效果（无论划过多少次都不会产生金币），但这类圆环不影响佐罗完成`Z`字。

佐罗划`Z`的起始位置有时候会有些偏，导致`Z`的部分轨迹落在石板之外（即：部分轨迹是凌空划出的），但这不影响落在石板上的轨迹。

假设石板之前从来没有被划过，请计算佐罗连续划多次`Z`字，每次可获得的金币数量。

输入格式:

第一行是不超过`20`的正整数`N`，表示石板上有`N`行、`N`列圆环。

接下来`N`行，每行有`N`个字符，表示石板上圆环的种类，按照从上往下、自左向右的顺序与石板上的圆环对应：

- `0` 表示普通圆环
- `$` 表示幸运圆环
- `*` 表示金刚圆环
- `#` 表示损坏圆环

接下来一行，是一个不超过`50`的正整数`K`，表示佐罗连续划了`K`次

最后`K`行，依次给出划的`Z`字的尺寸和位置，每行是一次`Z`，格式为三个整数`d x y`，用空格分隔，其中`d`是`Z`的尺寸（2≤*d*≤5），`x`是`Z`字起始位置的行坐标（0≤*x*<*N* ），`y`是`Z`字起始位置的列坐标（0≤*y*<*N*）。

输出格式:

对于输入的`K`次`Z`字，输出对应有`K`行，每行是一次`Z`字所获得的金币数量。

输入样例:

```in
6
0#0000
000000
0000#0
*$0000
00#000
00#00$
5
3 2 0
2 3 0
3 2 1
4 4 3
2 3 5
```

输出样例:

```out
1
0
3
2
1
```





#### 切分表达式

四则运算表达式由**运算数**（必定包含`数字`，可能包含`正或负符号`、`小数点`）、**运算符**（包括`+`、`-`、`*`、`/`）以及小括号（`(`和`)`）组成，每个运算数、运算符和括号都是一个*token*（标记）。现在，对于给定的一个四则运算表达式，请把她的每个token切分出来。题目保证给定的表达式是正确的，不需要做有效性检查。

输入格式:

在一行中给出长度不超过40个字符的表达式，其中没有空格，仅由上文中token的字符组成

输出格式:

依次输出表达式中的tokens，每个token占一行。

输入样例:

```in
32*((2-2)+5)/(-15)
```

输出样例:

```out
32
*
(
(
2
-
2
)
+
5
)
/
(
-15
)
```





#### 括号匹配

检查一段C语言代码的小括号`( )`、 中括号 `[ ]` 和大括号`{ }` 是否匹配。

输入格式:

在一行中输入一段C语言代码，长度不超过1000个字符（行末以换行符结束）。

输出格式:

第一行输出左括号的数量和右括号的数量，中间以一个空格间隔。

若括号是匹配的，在第二行打印`YES`，否则打印`NO`。

输入样例1:

```in
for(int i=0; i<v; i++){ visited[i] = 0; for(int j=0; j<v; j++) scanf("%d",&(g->Adj[i][j])); }
```

输出样例1:

```out
8 8
YES
```

输入样例2:

```
for(int i=0; i<v; i++) a(i]=0;
```

输出样例2:

```
2 2
NO
```





#### 一元多项式的乘法与加法运算

设计函数分别求两个一元多项式的乘积与和。

输入格式:

输入分2行，每行分别先给出多项式非零项的个数，再以指数递降方式输入一个多项式非零项系数和指数（绝对值均为不超过1000的整数）。数字间以空格分隔。

输出格式:

输出分2行，分别以指数递降方式输出乘积多项式以及和多项式非零项的系数和指数。数字间以空格分隔，但结尾不能有多余空格。零多项式应输出`0 0`。

输入样例:

```in
4 3 4 -5 2  6 1  -2 0
3 5 20  -7 4  3 1
```

输出样例:

```out
15 24 -25 22 30 21 -10 20 -21 8 35 6 -33 5 14 4 -15 3 18 2 -6 1
5 20 -4 4 -5 2 9 1 -2 0
```





#### String类

其构造函数应至少包含默认构造、从String拷贝构造、从c风格字符串构造。

成员函数：

```
size_t length(); // 获取长度
const char* c_str(); // 获取c风格字符串
String substr(size_t pos, size_t count); // 获取子串
size_t find(const char* str, size_t pos = 0); // 查询子串位置

// 重载：赋值、拼接、比较、流运算符
```





#### 地图模拟器

定义并实现一个Robot类，其中应包含Robot的各类状态，如：所处坐标、朝向。

成员函数：		

```
turn_left(); // 左转90度
turn_right(); // 右转90度
move_forward(); // 前进
get_x(); // 获取x坐标
get_y(); // 获取y坐标
```

主程序中，使用`std::vector<std::vector<int>>`来表示一个10x10的地图。0代表空地，1代表障碍物。你可以手动硬编码一个地图。定义地图右下角为终点。

创建一个Robot对象，并将其放置在地图的某个有效起始位置（例如 (0, 0)）。

定义一个指令字符串，例如 "FFRFLF" (F: 前进, L: 左转, R: 右转)。

遍历指令字符串，并调用Robot对象的相应方法来更新其状态。

在每次调用 move_forward() **之前**，必须进行**碰撞检测**。你需要计算出机器人移动后的目标位置，检查该位置是否越界或为障碍物。如果会发生碰撞，则机器人**不移动**并打印一条警告信息。

在所有指令执行完毕后，打印出机器人的最终坐标和朝向。



拓展：给出一个程序，用于计算从当前位置到终点的最短路径。



#### 终端基础命令

TO BE DONE



#### Hello, OpenCV!

读取一张本地图片，将其从彩色（BGR）转换为灰度图与HSV空间，然后并排显示原始图、灰度图、HSV。

将这张图片的原始图进行高斯滤波后二值化，创建一个滑动条控制二值化阈值，并令阈值改变的效果实时更新。





#### 识别特定颜色的物体

打开你的电脑摄像头，实时识别并框选出画面中特定颜色的物体（例如，一个蓝色的瓶盖或一张红色的卡片），将过程保存为视频。

输入一张指定图片，标注出图中的彩色图形并计算面积，创建一个滑动条，调整图形面积阈值。

分别找出指定的 3 张图片里的蓝色指示牌和绿色指示牌，并将它们写入到 green、blue 两个文件夹中。用矩形框出指示牌，同时写入的指示牌需要尽量拉正。






#### 简易装甲板识别

设计并实现一个实时识别并框出装甲板的算法流程，装甲板可前往实验室拿取。

扩展：同时识别多块装甲板。

更有难度的扩展：尝试预测装甲板的预测轨迹，并在视频中标注装甲板的可能的下一帧位置。





#### 相机标定

编写程序，对相机进行标定，计算出相机内参并保存。

在网上搜索“棋盘格图片”，打印一张清晰的、A4纸大小的棋盘格（例如9x6的内部角点）。

使用你要用的摄像头，从不同角度、不同距离拍摄15-20张棋盘格的照片。确保棋盘格在图像的各个位置都出现过（中央、边缘、角落）。

对每一张照片，使用 `cv::findChessboardCorners()` 函数来寻找棋盘格的角点。

使用 `cv::calibrateCamera()` 函数，传入所有照片中找到的角点坐标（图像坐标系）和它们对应的理论3D坐标（世界坐标系，可以自己定义），计算出**相机内参矩阵 (Camera Matrix)** 和**畸变系数 (Distortion Coefficients)**。

将计算出的这两个矩阵保存到一个文件中（例如.xml或.yaml格式），方便以后直接读取使用。





#### 实时位姿解算

编写程序，对物体进行实时位姿解算。

在你的“简易装甲板识别”作业中，首先从文件中读取之前保存的相机内参矩阵和畸变系数。

当你检测到一个装甲板时，精确地获取其四个顶点的像素坐标。**注意：这四个点的顺序必须与你下一步定义的3D模型点的顺序严格对应！** 

根据RoboMaster规则手册，查出装甲板的实际物理尺寸。定义一个包含四个三维点的`std::vector`，作为`solvePnP`的输入。

调用 `cv::solvePnP()` 函数，传入2D图像点、3D模型点、相机内参和畸变系数。函数会返回旋转向量`rvec`和平移向量`tvec`。

在控制台打印出计算得到的平移向量`tvec`。它的三个分量(x, y, z)就代表了装甲板中心在相机坐标系下的三维坐标。观察这个坐标，看看它是否和你移动装甲板的直观感受一致（比如，拿远了z值变大）。





#### 基于卡尔曼滤波的装甲板追踪器

这是视觉部分的最后一项挑战，它将把你之前的所有工作串联起来，构建一个真正可用的自瞄算法核心。

**前提：** 确保你已经完成了“装甲板位姿解算”的作业，并且能够稳定地输出装甲板的三维坐标。

**第一步：定义状态和测量**

**状态向量 `x`**：我们关心的是装甲板在三维空间中的运动。一个简单的模型是匀速运动模型。因此，我们的状态向量至少需要包含位置和速度。例如：$x = [px, py, pz, vx, vy, vz]^T$ ($位置x,y,z$ 和 $速度x,y,z$)。

**测量向量 `z`**：我们的传感器（相机+解算算法）只能直接测量到位置，而无法直接测量速度。因此，测量向量是：$z = [px_meas, py_meas, pz_meas]^T$。

**第二步：初始化 `cv::KalmanFilter`**

1. 创建一个`cv::KalmanFilter`对象。你需要根据你的状态向量和测量向量的维度来设置它（例如，6个状态量，3个观测量）。

2. **设置核心矩阵**：这是最关键的一步。你需要理解并设置以下矩阵：

  **状态转移矩阵 F (transitionMatrix)**：描述了状态如何从上一时刻转移到当前时刻。

  **测量矩阵 H (measurementMatrix)**：描述了如何从状态向量中提取出测量向量。

  **过程噪声协方差矩阵 Q (processNoiseCov)**：表示你对运动模型的信任程度。如果Q很小，说明你认为目标严格遵守匀速运动。

  **测量噪声协方差矩阵 R (measurementNoiseCov)**：表示你对观测量的信任程度。如果你的装甲板识别和解算结果抖动很大，R就应该大一些。

**第三步：实现追踪循环**

在你的主循环中，执行以下逻辑：

**预测**：在每一帧的开始，无论是否找到目标，都首先调用`kalmanFilter.predict()`。这将给出目标的先验预测位置。

**检测与更新**：

​		**如果检测到了装甲板**：获取其三维坐标作为**观测量 `z`**，调用`kalmanFilter.correct(z)`，用观测量去修正预测值，得到一个最优的后验估计状态。

​		**如果没检测到装甲板**：**不**调用`correct()`函数。此时，卡尔曼滤波器的状态就是`predict()`之后的状态。

**获取结果**：从卡尔曼滤波器的状态向量`statePost`中，提取出平滑后的位置坐标 `(px, py, pz)` 用于当前瞄准。

同时，提取出速度 $(vx, vy, vz)$。计算出你的系统延迟 `delay`（例如50ms），那么预测位置就是 $(px + vx*delay, py + vy*delay, pz + vz*delay)$。这就是你要发送给云台的**最终目标点**。

**第四步：目标丢失处理**

简单的卡尔曼滤波器不知道目标是否永久丢失了。你需要自己添加一个简单的逻辑：设置一个计数器，如果连续N帧（例如15帧）都没有检测到目标，就认为目标丢失，重置追踪器。

**第五步：可视化验证**

为了验证你的追踪器效果，请在屏幕上同时绘制：

​		一个**红色的框**代表**测量到**的装甲板位置。

​		一个**绿色的框**代表卡尔曼滤波**估计/预测**的装甲板位置。

你会直观地看到：当红框抖动时，绿框依然平滑；当红框短暂消失时，绿框会继续沿着之前的轨迹运动一小段距离。



拓展一：使用**扩展卡尔曼滤波器**

拓展二：使用**加速度模型**代替匀速模型





#### 实现手写数字识别

利用PyTorch下载MNIST数据集，编写自己的数据集构建与加载、前向与反向传播、模型效果展示等代码。

整体流程请参照d2l教程。



#### 构建、训练并部署一个YOLO装甲板检测器

这个项目将带你走完一个真正的深度学习项目全流程。

**第一步：数据集的准备**

在实验室录制包含各种装甲板的视频（不同机器人、不同角度、不同光照、运动模糊等），将视频按一定间隔（如每10帧）截取为图片，也可以从往年的比赛录像中截取图片，增加数据的多样性。

下载并学习使用**LabelMe**开源标注工具，在每一张图片上，用矩形框框出所有的装甲板，为每个框分配一个类别（例如 'blue_1', 'red_sentry' 等，或者简单地分为 'armor'），将标注结果导出为YOLO训练所需的`.txt`格式。

**第二步：模型训练**

参照YOLO官网的教程，选取合适的YOLO版本与模型大小，利用已构建的数据集进行训练。

**第三步：模型部署与C++集成**

训练出的模型（例如 `best.pt`）是一个Python文件，无法直接在我们的C++主程序中使用。我们需要进行**模型部署**。

首先需要将PyTorch的`.pt`模型转换为一个更通用的、适合推理的格式，最常用的是 **ONNX (Open Neural Network Exchange)**。

**ONNX Runtime**是一个跨平台的推理引擎，可以直接在C++中加载`.onnx`模型并进行推理。配置相对简单，是入门部署的好选择。

在你的C++视觉项目中，集成ONNX Runtime的库，编写一个Detector类，负责加载模型、预处理输入图像（resize, normalize等）、执行推理、以及后处理输出（NMS、解析边界框和置信度等）。

用你新实现的深度学习Detector，**替换掉**原来基于颜色和形态学的传统装甲板识别模块。

Detector的输出（一个包含多个装甲板边界框的列表），将作为后续**PnP姿态解算**和**卡尔曼滤波追踪**模块的输入。

至此，你已成功将整个视觉算法升级为现代化的深度学习方案。
